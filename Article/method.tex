\clearpage
\newpage

\section{New methods}

%% Présenter le problème et la factorisation matricielle
%%
%%

In this section we present two new algorithms for estimating individual admixture coefficients and ancestral genotype frequencies assuming $K$ ancestral populations ($K$ is estimated). The new algorithms require individual geographic coordinates to perform estimation from sampled genotypes.

\paragraph{$Q$ and $G$-matrices} Consider a genotypic matrix, {\bf Y}, recording data for $n$ individuals at $L$ polymorphic loci for a $p$-ploid species (common values for $p$ are $p = 1,2$). For autosomal SNPs in a diploid organism, the genotype at locus $\ell$  is an integer number 0, 1 or 2, corresponding to the number of reference alleles at this locus. In our algorithms, disjunctive forms are used  to encode each genotypic value as the indicator of a heterozygote or a homozygote locus (Frichot et al. 2014). For $p$-ploid organisms, there are $(p+1)$ possible genotypic values at each locus, and each value corresponds to a unique disjunctive form. While our focus is on SNPs, the algorithms presented in this section extend to multi-allelic loci without loss of generality. 
The method can be easily extended to genotype likelihoods by using the likelihood to encode each genotypic value~\citep{Korneliussen2014}.

Our algorithms provide statistical estimates for the $Q$-matrix which contains the admixture coefficients, $q_{ik}$, for each sampled individual, $i$, and each ancestral population, $k$. The algorithms also provide estimates for the $G$-matrix, for which the entries, $g_{k\ell}(j)$, correspond to the frequency of genotype $j$ at locus $\ell$ in population $k$. Obviously, the $Q$ and $G$-matrices must satisfy the following set of probabilistic constraints 

$$
\quad {\bf Q},{\bf G} \geq 0 \, , \quad  \sum_{k=1}^K q_{ik} = 1 \, , \quad \sum_{j=0}^p g_{k\ell}(j) = 1 \, , \quad j = 0,1,\dots, p,
$$
for all $i$ and $\ell$. Using disjunctive forms and the law of total probability, estimates of {\bf Q} and {\bf G} can be obtained by factorizing the genotypic matrix as follows ${\bf Y}$=${\bf Q}\,{\bf G}^T$ (Frichot et al. 2014). Thus the inference problem can be solved by using constrained nonnegative matrix factorization methods~\citep{Lee1999, Cichocki2009}.  In the sequel, we shall use the notations  $\Delta_Q$ and  $\Delta_G$ to represent the sets of probabilistic constraints put on the {\bf Q} and {\bf G} matrices respectively. 




 \paragraph{Geographic weighting} Geography is introduced in the matrix factorization problem by using weights that impose regularity constraints on ancestry estimates over geographic space. The definition of geographic weights is based on the spatial coordinates of the sampling sites, $(x_i)$. Samples close to each other are given more weights than samples that are far apart. The computation of the weights starts with building a nearest-neighbor graph from the sampling sites. Then the nearest-neighbor graph is used to define the weight matrix as follows


$$
w_{ij} = \exp( - {\rm dist}( x_i, x_j )^2/ \sigma^2)
$$

\noindent where dist$( x_i, x_j )$ denotes the geodesic distance between sites $x_i$ and  $x_j$, and $\sigma$ is a range parameter. In pratical implementations of the weight matrix, the number of neighbor is set to a fixed value ranging between 10 and 20. By default, the range parameter is set to 5 percent of the average distance between pairs of sites. Values for the range parameter may also be investigated by using spatial variograms~\citep{Cressie1993}. 

Next, we introduce the {\it Laplacian matrix} associated with the geographic weight matrix, {\bf W}. The Laplacian matrix is defined as ${\bf \Lambda}$ =  {\bf D} $-$ {\bf W}  where  {\bf D} is a diagonal matrix with entries 
$d_{ii} = \sum_{j = 1}^n w_{ij}$,  for  $i = 1, \dots, n$~\citep{Belkin2003}. Elementary matrix algebra shows that 

$$
 {\rm Tr} ({\bf Q}^T {\bf \Lambda} {\bf Q})  = \frac12 \sum_{i,j = 1}^n  w_{ij}  \|   q_{i.}  - q_{j.} \|^2 \, ,
$$

 \noindent  where $\|  u \|^2$ is the square norm of the vector $u$~\citep{DengCai2011}. Assuming that geographically close individuals are more likely to share ancestry than individuals at distant sites  is thus equivalent to minimizing the quadratic form ${\cal C}({\bf Q}) ={\rm Tr} ({\bf Q}^T {\bf \Lambda} {\bf Q})$ while estimating the matrix ${\bf Q}$. 

\paragraph{Least-squares minimization problems} Estimating the matrices ${\bf Q}$ and {\bf G } is performed through the minimization of the least-squares functional defined as follows

\begin{equation}
\min {\rm LS}({\bf Q}, {\bf G}) =   \|  {\bf Y} - {\bf QG}^T \|^2_{\rm F} +  \alpha \, {\cal C}({\bf Q}) \, , 
\label{eq:LS}
\end{equation}

 \noindent  under the sets of constraints $\Delta_Q$ and  $\Delta_G$~\cite{Caye2016}. Here, the notation $\|  {\bf M}  \|_{\rm F}$ denotes the Frobenius norm of a matrix, {\bf M}. A regularization parameter, $\alpha$, controls the regularity of ancestry estimates over geographic space.  Large values of $\alpha$ imply that ancestry coefficients have similar values for nearby individuals, whereas small values ignore spatial autocorrelation in observed allele frequencies. In pratice, the default value for the regularization parameter is set to $\alpha = (p+1)L/K \lambda_{\max}$, where $\lambda_{\max}$ is the largest eigenvalue of the Laplacian matrix. Using the least-squares approach, the number of ancestral populations, $K$, can be chosen after the evaluation of a cross-validation criterion for each $K$~\citep{Alexander2011, Frichot2014, Frichot2015}.  


\paragraph{The Alternating Quadratic Programming (AQP) method} Because the poly\-edrons $\Delta_Q$ and  $\Delta_G$ are convex sets and the LS function is convex with
respect to one of the variables ${\bf Q}$ or ${\bf G}$ when the other one is fixed, the above least-squares estimation problem is amenable to the application of block coordinate descent~\citep{Bertsekas1995}. The APQ algorithm starts from initial values for the $G$ and $Q$-matrices, and alternates two steps. The first step computes the matrix {\bf G} while  {\bf Q} is kept fixed, and second step permutates the roles of {\bf G} and {\bf Q}.  Let us assume that {\bf Q} is fixed and write {\bf G} in a vectorial form, $g = {\rm vec({\bf G})}$. The first step of algorithm actually solves the following quadratic programming problem. Find  

$$
g^\star = \arg \min  ( -2  v^T_Q \, g + g^T {\bf D}_Q g ) \, ,  
$$

\noindent where $g \in \Delta_G$, ${\bf D}_Q = {\bf I}_{(p+1)L} \otimes {\bf Q}^T {\bf Q}$ and $v_Q = {\rm vec}({\bf Q}^T {\bf Y})$. Here, $\otimes$ denotes the Kronecker product and ${\bf I}_d$ is the identity matrix with $d$ dimensions.  Now, consider that {\bf G} is the value obtained after the first step of the algorithm, and write {\bf Q} in a vectorial form, $q = {\rm vec({\bf Q})}$. The second step solves the following quadratic programming problem. Find

$$  
q^\star = \arg \min ( -2 v^T_G \, q + q^T {\bf D}_G q ) \,  ,
$$


\noindent where  $q \in \Delta_Q$, ${\bf D}_G = {\bf I}_{n} \otimes {\bf G}^T {\bf G }+ \alpha {\bf \Lambda}  \otimes {\bf I}_K$ and $v_G = {\rm vec}({\bf G}^T{\bf  Y}^T)$. According to the Corollary 2 of ~\cite{Grippo2000} we can directly write the following convergence result:
\begin{thm}
	The AQP algorithm converges to a critical point of the problem~\ref{eq:LS}.
\end{thm}
Thus, using AQP provides theoretical guarantees that the $Q$ and $G$-matrix estimates are correctly computed, a property lacking for other algorithms, such as {\tt structure} or {\tt tess3}.  The computation of the second step of the AQP algorithm has an algorithmic complexity of order $O(n^2)$ which does not improve over~\cite{Caye2016}Õs method, and can be problematic for large samples ($n$ is the sample size). 


\paragraph{Alternating Projected Least-Squares (APLS)} In this paragraph, we introduce an APLS estimation algorithm which approximates the solution of the least-squares problem, and for which the algorithmic complexity is of order $O(n)$, with $n$ the number of samples. The APLS algorithm starts from initial values of the $G$ and $Q$-matrices, and alternates two steps. The matrix {\bf G} is computed  while  {\bf Q} is kept fixed, and {\it vice versa}. Assume that the matrix {\bf Q} is known. The first step of the APLS algorithm solves the following minimization problem. Find 

$$
{\bf G}^\star = \arg \min  \|  {\bf Y} - {\bf QG}^T \|^2_{\rm F} \, ,
$$

\noindent where ${\bf G}^\star$ is a nonnegative matrix. This operation can be done by considering $(p+1)L$ independent minimization problems running in parallel. It is followed by a projection of ${\bf G}^\star$ on the polyedron of constraints $\Delta_G$. For the second step, assume that {\bf G} is set to the value obtained after the first step is completed. We compute the eigenvectors, {\bf U}, of the Laplacian matrix, and we define the diagonal matrix diag$({\bf \Lambda})$ formed by the eigenvalues of ${\bf \Lambda}$ (The eigenvalues of ${\bf \Lambda}$ are non-negative real numbers). According to the spectral theorem, we have

$$
{\bf \Lambda} = {\bf U}^T {\rm diag}({\bf \Lambda}) {\bf U} \, .
$$

\noindent  After this operation, we project the data matrix {\bf Y} on the basis of eigenvectors as follows

$$
{\rm proj} ({\bf Y}) = {\bf U}{\bf Y} \, , 
$$

\noindent and, for each individual, we solve the following minimization problem

$$
q_i^\star = \arg \min  \|  {\rm proj} ({\bf Y})_i  - {\bf G}^Tq \|^2 + \alpha \lambda_i   \| q \|^2  \, ,
$$

\noindent where  proj({\bf Y}$)_i$ is the $i$th row of the projected data matrix, proj({\bf Y}). The solutions, $q_i$, are then concatenated into a matrix, {\rm conc}(q), and ${\bf Q}$ is defined as ${\bf U}^T {\rm conc}(q)$ projected on the polyedron $\Delta_Q$. The complexity of the algorithm is driven by the diagonalization of the Laplacian matrix, which has complexity of order $O(n)$. While the theoretical convergence properties of AQP algorithms are lost for APLS algorithms, the APLS algorithms are expected to be good approximations of AQP algorithms.



\paragraph{Estimation with {\tt tess3}}  The algorithm implemented in \cite{Caye2016}Õs  program also provides approximation of the least-squares problem. The {\tt tess3} algorithm first computes the Cholesky decomposition of the Laplacian matrix. Then, by a change of variables, the least-squares problem is transformed into a sparse nonnegative matrix factorization problem~\citep{Caye2016}.  Solving the sparse non-negative matrix factorization problem relies on the application of existing methods~\citep{Kim2011, Frichot2014}. The methods implemented in {\tt tess3} have an algorithmic complexity that increases linearly with the number of loci and the number of clusters. They lead to estimates that accurately reproduce those of the Monte Carlo algorithms implemented in the Bayesian method {\tt tess} 2.3~\citep{Caye2016}. Like for the AQP method, the {\tt tess3} algorithms have an algorithmic complexity that increases quadratically with the sample sizes.  




\paragraph{Ancestral population differentiation statistics} Assuming $K$ ancestral populations, the $Q$ and $G$-matrices  obtained from the AQP and from the APLS algorithms were used to compute single-locus estimates of a population differentiation statistic similar to $F_{\rm ST}$~\citep{Martins2016}, as follows

$$
F^{Q}_{\rm ST} = 1 - \sum_{k=1}^K  q_k \frac{f_k (1-f_k)}{f(1-f)} \, ,
$$

\noindent where $q_k$ is the average of ancestry coefficients over sampled individuals, $q_k = \sum_{i =1}^n q_{ik}/n$, for the cluster $k$, $f_k$ is the ancestral allele frequency in population $k$, and $f = \sum_{k = 1}^K q_k f_k$ (Martins et al. 2016). The locus-specific statistics were used to perform statistical tests of neutrality at each locus, by comparing the observed values to their expectations from the genome-wide background. The test was based on the squared $z$-score statistic, $z^2 = (n-K) F^{Q}_{\rm ST}/(1 - F^{Q}_{\rm ST})$, for which a  chi-squared distribution with $K-1$ degrees of freedom was assumed under the null-hypothesis~\citep{Martins2016}. The calibration of the null-hypothesis was achieved by using genomic control to adjust the test statistic for background levels of population structure~\citep{Devlin1999, Francois2016}. After recalibration of the null-hypothesis, the control of false discovery rates was achieved by using the Benjamini-Hochberg algorithm~\citep{Benjamini1995}.


\paragraph{{\tt R} package} We implemented the AQP and APLS algorithms in the {\tt R} package {\tt tess3r}, available from Github and submitted to the Comprehensive R Archive Network (R Core Team, 2016).  


\section{Simulated and real data sets}
\paragraph{Coalescent simulations} We used the computer program {\tt ms} to perform coalescent simulations of neutral and outlier SNPs under spatial models of admixture~\citep{Hudson2002}. Two ancestral populations were created from the simulation of Wright\rq{}s two-island models. The simulated data sets contained admixed genotypes for $n$ individuals for which the admixture proportions varied continuously along a longitudinal gradient~\citep{Durand2009, Francois2010}. In those scenarios, individuals at each extreme of the geographic range were representative of their population of origin, while individuals at the center of the range shared intermediate levels of ancestry in the two ancestral populations~\citep{Caye2016}. For those simulations, the $Q$ matrix, ${\bf Q}_0$, was explicitly described by the spatially varying individual admixture proportions.


Neutrally evolving ancestral chromosomal segments were generated by simulating DNA sequences with an effective  population size $N_0 = 10^6$ for each ancestral population. The mutation rate per bp and generation was set to $\mu = 0.25 \times 10^{-7}$, the recombination rate per generation was set to $r = 0.25 \times 10^{-8}$, and the parameter $m$ was set to obtained neutral levels of $F_{\rm ST}$ ranging between values of $0.005$ and $0.10$. The number of base pairs for each DNA sequence was varied between 10k to 300k to obtain numbers of polymorphic locus ranging between 1k and 200k after filtering out SNPs with minor allele frequency lower than 5$\%$.  To create SNPs with values in the tail of the empirical distribution of $F_{\rm ST}$,  additional ancestral chromosomal segments were generated by simulating DNA sequences with a migration rate $m_s$ lower than $m$. The simulations reproduced the reduced levels of diversity and the increased levels of differentiation expected under hard selective sweeps occurring at one particular chromosomal segment in one ancestral population.  For each simulation, the sample size  was varied in the range $n =$ 50-700.

 We compared the AQP and APLS algorithm estimates with those obtained with the {\tt tess3} algorithm.  Each program was run 5 times.  Using $K = 2$ ancestral populations, we computed the root mean squared error (RMSE) between the estimated and known values of the $Q$-matrix, and between  the estimated and known values of the $G$-matrix. 
To evaluate the benefit of spatial algorithms, we compared the statistical errors of APLS algorithms to the errors obtained with a method that reproduces the outputs of the {\tt structure} program accurately ({\tt snmf}, Frichot et al. 2014, Frichot and Francois 2015).  To quantify the performances of neutrality tests as a function of ancestral and observed levels of $F_{\rm ST}$, we used the area under the precision-recall curve (AUC) for several values of the selection rate.  Subsamples from a real data set were used to perform a runtime analysis of the AQP and APLS algorithms ({\it A. thaliana} data, see below). Runtimes were evaluated by using a single computer processor unit Intel Xeon 2.0 GHz.

\paragraph{Application to European ecotypes of {\it Arabidopsis  thaliana}} We used  the APLS algorithm to survey spatial population genetic structure and to investigate the molecular basis of adaptation  by considering SNP data from 1,095  European ecotypes of the plant species {\it A. thaliana} (214k SNPs, \cite{Horton2012}). The cross-validation criterion was used to evaluate the number of clusters in the sample, and a statistical analysis was performed to evaluate the range of the variogram from the data~\citep{Cressie1993}. We used {\tt R} functions of the {\tt tess3r} package to display interpolated admixture coefficients on a geographic map of Europe (R Core team 2016). A gene ontology enrichment analysis using the software AMIGO~\citep{Carbon2009} was performed in order to evaluate which molecular functions and biological processes might be involved in local adaptation in Europe.







